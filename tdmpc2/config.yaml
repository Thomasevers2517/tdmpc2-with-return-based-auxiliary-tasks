defaults:
    # - override hydra/launcher: submitit_local
    - override hydra/launcher: basic

# environment
task: reacher-easy
obs: rgb
episodic: false

# evaluation
checkpoint: ???
eval_episodes: 10
eval_freq: 50000

# training
utd_ratio: 1
ac_utd_multiplier: 1
reset_agent_freq: 400_000_000   # number of ac updates between resets of actor and critic networks so steps / (utd_ratio * ac_utd_multiplier) is number of env steps between resets

steps: 4_000_000
batch_size: 256
reward_coef: 0.1
value_coef: 0.1
termination_coef: 1
consistency_coef: 20
rho: 0.5
lr: 3e-4
enc_lr_scale: 0.3
grad_clip_norm: 20
tau: 0.01
discount_denom: 5
discount_min: 0.95
discount_max: 0.995
buffer_size: 1000_000

pin_memory: true
prefetch: 4

exp_name: default
data_dir: ???

# planning
mpc: true
iterations: 6
num_samples: 512
num_elites: 64
num_pi_trajs: 24
horizon: 3
min_std: 0.05
max_std: 2
temperature: 0.5

# actor
log_std_min: -10
log_std_max: 2
entropy_coef: 1e-4

# critic
num_bins: 101
vmin: -10
vmax: +10

# architecture
model_size: ???
num_enc_layers: 2
enc_dim: 256
num_channels: 32
mlp_dim: 512
latent_dim: 512
task_dim: 96
num_q: 5
dropout: 0.01
simnorm_dim: 8

# logging
wandb_project: test_auxiliary
wandb_entity: thomasevers9
wandb_silent: false
enable_wandb: true
save_csv: true

# misc
compile: false
compile_type: reduce-overhead  # 'default', 'reduce-overhead', 'max-autotune'
save_video: false
save_agent: false
seed: 1


nvtx_profiler: false           # If true: add lightweight NVTX record_function ranges (disables compile for clarity).

# ---------------------------------------------------------------------------
# Multi-gamma auxiliary value supervision (RESEARCH FEATURE)
# ---------------------------------------------------------------------------
# Goal: improve representation learning by supervising additional discounted
#       state-value predictions at multiple discount factors (gammas) WITHOUT
#       affecting action selection, planning, or policy targets.
# Invariants:
#   * Primary (existing) Q ensemble remains unchanged and drives planning.
#   * Auxiliary heads are training-only. Gradients flow into shared trunk.
#   * When disabled or only 1 gamma is given, behavior matches baseline.
# ---------------------------------------------------------------------------
multi_gamma_gammas: [0.9, 0.95]              # Auxiliary discounts ONLY (do not include primary). Empty => feature disabled.
joint_aux_dim_mult: 1                                     # Non-empty length ≤ 6. Primary discount auto-prepended internally.
multi_gamma_head: joint             # Head architecture: 'joint' (single Linear -> G_aux*K) or 'separate' (one Linear per aux γ).
multi_gamma_loss_weight: 0.1        # Scalar weight applied to MEAN auxiliary loss (after averaging over aux gammas & time).
multi_gamma_debug_logging: true    # If True: emit richer per-gamma diagnostics (heavier overhead).
multi_gamma_log_num_examples: 4    # Max examples included in debug snapshots (targets vs preds) when debug logging.
auxiliary_value_ema: true

use_bfloat16: false            # If true: use bfloat16 precision with autocast where applicable (saves memory, may be faster).

distracted_dynamic: true    # 'dynamic' (changing distractors) or 'static' (fixed distractors)
distracted_difficulty: medium   # 'easy', 'medium', 'hard'
davis_dataset_path: /users/thomasevers/users/thomas/auxilarysignalsworldmodels/tdmpc2/tdmpc2/envs/custom_envs/distracting_control/DAVIS/JPEGImages/480p  # Path to DAVIS dataset for Distracting Control tasks
# convenience
work_dir: ???
task_title: ???
multitask: ???
tasks: ???
obs_shape: ???
action_dim: ???
episode_length: ???
obs_shapes: ???
action_dims: ???
episode_lengths: ???
seed_steps: ???
bin_size: ???

# ----------------------------------------------------------------------------
# Hydra logging and run directory configuration
# Routes Python logging to both console and a train.log file in the Hydra run dir
# ----------------------------------------------------------------------------
hydra:
    job:
        chdir: true
        env_set:
            PYTHONUNBUFFERED: "1"
    run:
        dir: logs/${now:%Y%m%d_%H%M%S}
    job_logging:
        formatters:
            simple:
                format: "%(asctime)s | %(levelname)s | %(name)s | %(message)s"
                datefmt: "%H:%M:%S"
        handlers:
            file:
                class: logging.FileHandler
                formatter: simple
                filename: train.log
                mode: a
            console:
                class: logging.StreamHandler
                formatter: simple
        root:
            level: INFO
            handlers: [file, console]
