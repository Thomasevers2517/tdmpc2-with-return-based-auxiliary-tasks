# Sweep 14.4: Current defaults + dual_policy + critic_target=rollout
#
# Goal: Test whether just enabling dual_policy and critic_target_source=
# replay_rollout on top of the CURRENT default config reproduces 162
# performance, without carrying over all the other 162 settings.
#
# {hopper-hop, dog-run} Ã— 5 seeds = 10 runs
#
# Changes from current defaults:
#   dual_policy_enabled: true (default: false)
#   critic_target_source: replay_rollout (default: replay_true)
#   optimistic_entropy_mult: 1 (now default, was 100)
#   optimistic_policy_value_std_coef: 1 (now default, was 0)
#
# Everything else stays at current defaults:
#   num_pi_trajs: 24, num_rollouts: 1, consistency_coef: 10,
#   td_target_std_coef: 0, final_rho: -1, ema_value_planning: false,
#   num_reward_heads: 1, num_reward_layers: 2, reward_dim_div: 1,
#   num_samples: 512, max_std: 2, dropout: 0.01,
#   log_std_min: -5, log_std_max: 1,
#   planner_value_std_coef_train: 0, planner_value_std_coef_eval: 0,
#   enc_lr_step_scale: 1

program: tdmpc2/train.py
project: tdmpc2-tdmpc2
method: grid
command:
  - ${env}
  - python
  - ${program}
  - ${args_no_hyphens}
parameters:
  task:
    values: [hopper-hop, dog-run]
  seed:
    values: [1, 2, 3, 4, 5]

  #############################################
  # THE TWO KEY CHANGES
  #############################################
  dual_policy_enabled:
    value: true
  critic_target_source:
    value: replay_rollout

  #############################################
  # DUAL POLICY SETTINGS (needed for it to work)
  #############################################
  optimistic_policy_value_std_coef:
    value: 1
  optimistic_entropy_mult:
    value: 1

  #############################################
  # EVERYTHING ELSE: CURRENT DEFAULTS (explicit)
  #############################################
  planner_num_dynamics_heads:
    value: 4
  td_target_dynamics_reduction:
    value: mean
  td_target_std_coef:
    value: 0
  local_td_bootstrap:
    value: true
  policy_value_std_coef:
    value: 0
  planner_value_std_coef_train:
    value: 0
  planner_value_std_coef_eval:
    value: 0
  dynamics_prior_scale:
    value: 0
  value_prior_scale:
    value: 0
  rollout_head_strategy:
    value: split
  jacobian_correction_scale:
    value: 1.0
  steps:
    value: 100000
  eval_freq:
    value: 10000
  utd_ratio:
    value: 4
  value_update_freq:
    value: 2
  pi_update_freq:
    value: 1

  #############################################
  # LOGGING
  #############################################
  enable_wandb:
    value: true
  wandb_project:
    value: tdmpc2-tdmpc2
  wandb_entity:
    value: thomasevers9
  compile:
    value: true
  save_video:
    value: false
