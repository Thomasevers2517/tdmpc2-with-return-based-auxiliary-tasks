# Sweep 12.1: Optimistic TD targets + distributional prior scale
# 2 tasks × 3 seeds × 2 td_target_std_coef × 2 value_prior_scale = 24 runs
#
# Tests whether:
# 1. Optimistic TD targets (td_target_std_coef=1) help by treating uncertain
#    reward/value as promising (a chance of reward is seen as good).
# 2. Distributional prior scale (value_prior_scale) affects exploration diversity
#    in reward and value heads via the new shift_scale_distribution mechanism.
# 3. Two reward heads provide useful reward disagreement signal.

program: tdmpc2/train.py
project: tdmpc2-tdmpc2
method: grid
command:
  - ${env}
  - python
  - ${program}
  - ${args_no_hyphens}
parameters:
  task:
    values:
      - hopper-hop
      - dog-run

  seed:
    values: [1, 2, 3]

  # --- Swept parameters ---
  td_target_std_coef:
    values: [0, 1]

  value_prior_scale:
    values: [0.1, 1.0]

  # --- Fixed parameters ---
  num_reward_heads:
    value: 2

  num_q:
    value: 5

  steps:
    value: 100000

  rollout_head_strategy:
    value: single

  num_rollouts:
    value: 1

  # Logging
  enable_wandb:
    value: true
  wandb_project:
    value: tdmpc2-tdmpc2
  wandb_entity:
    value: thomasevers9
  compile:
    value: true
  save_video:
    value: false
