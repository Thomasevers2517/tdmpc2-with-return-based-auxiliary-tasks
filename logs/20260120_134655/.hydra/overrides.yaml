- compile=True
- dropout=0
- ema_value_planning=True
- enable_wandb=True
- enc_lr_step_ratio=0.5
- end_dynamic_entropy_ratio=1
- entropy_action_dim_power=1
- eval_freq=10000
- eval_mean_head_reduce=False
- fix_kl_order=True
- hinge_coef=0
- iterations=6
- jacobian_correction_scale=1
- kl_scale_min=0.1
- local_td_bootstrap=True
- multi_gamma_loss_weight=0
- num_enc_layers=2
- num_pi_trajs=24
- num_q=2
- num_reward_heads=2
- num_samples=512
- num_value_layers=2
- optimistic_entropy_mult=100
- optimistic_policy_optimization_method=distillation
- optimistic_policy_value_std_coef=1
- pi_update_freq=1
- planner_num_dynamics_heads=2
- planner_use_all_heads_eval=True
- planner_value_std_coef_eval=-1
- planner_value_std_coef_train=0.3
- policy_optimization_method=distillation
- policy_value_std_coef=0
- prior_hidden_div=16
- prior_logit_scale=1
- prior_scale=0.1
- reanalyze_batch_size=32
- reanalyze_horizon=3
- reanalyze_interval=5
- reanalyze_iterations=4
- reanalyze_num_elites=64
- reanalyze_num_pi_trajs=24
- reanalyze_num_samples=512
- reanalyze_temperature=0.1
- reanalyze_value_std_coef=0
- save_video=False
- seed=1
- start_dynamic_entropy_ratio=1
- start_entropy_coeff=0
- steps=100000
- task=quadruped-walk
- td_target_dynamics_reduction=mean
- td_target_std_coef=0
- utd_ratio=4
- value_update_freq=2
- wandb_entity=thomasevers9
- wandb_project=tdmpc2-tdmpc2
