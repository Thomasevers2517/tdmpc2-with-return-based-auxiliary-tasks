{"eval/episode_reward": 13.641904830932617, "eval/episode_success": 0.0, "eval/episode_length": 500.0, "eval/step": 25000, "eval/episode": 49, "eval/elapsed_time": 1450.135110616684, "eval/steps_per_second": 17.239772912862243, "_timestamp": 1757525056.4714866, "_runtime": 2601.1926896572113, "_step": 43500, "train/episode_reward": 42.26901626586914, "train/episode_success": 0.0, "train/episode_length": 501, "train/episode_terminated": 0.0, "train/step": 43500, "train/episode": 86, "train/elapsed_time": 2598.4520721435547, "train/steps_per_second": 16.74073594288592, "train/consistency_loss": 0.004005827009677887, "train/reward_loss": 0.023053433746099472, "train/value_loss": 0.30250710248947144, "train/aux_value_loss_mean": 0.361792653799057, "train/termination_loss": 0.0, "train/total_loss": 0.14885185658931732, "train/aux_value_loss/g0_gamma0.9000": 0.37464579939842224, "train/aux_value_loss/g1_gamma0.9500": 0.3489395081996918, "train/grad_norm": 0.11063527315855026, "train/pi_loss": -0.08234159648418427, "train/pi_grad_norm": 2.5565453753984002e-08, "train/pi_entropy": -10.37981128692627, "train/pi_scaled_entropy": 3.435699701309204, "train/pi_scale": 1.5830729007720947}