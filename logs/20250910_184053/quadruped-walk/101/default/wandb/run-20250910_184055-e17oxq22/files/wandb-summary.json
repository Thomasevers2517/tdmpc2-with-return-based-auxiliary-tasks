{"eval/episode_reward": 28.82892417907715, "eval/episode_success": 0.0, "eval/episode_length": 500.0, "eval/step": 25000, "eval/episode": 49, "eval/elapsed_time": 1596.355479478836, "eval/steps_per_second": 15.660672275928027, "_timestamp": 1757525064.415871, "_runtime": 2609.057564020157, "_step": 40000, "train/episode_reward": 31.59128189086914, "train/episode_success": 0.0, "train/episode_length": 501, "train/episode_terminated": 0.0, "train/step": 40000, "train/episode": 79, "train/elapsed_time": 2606.4786987304688, "train/steps_per_second": 15.346375176395151, "train/consistency_loss": 0.0050677284598350525, "train/reward_loss": 0.1680622696876526, "train/value_loss": 0.34253233671188354, "train/aux_value_loss_mean": 0.5646986961364746, "train/termination_loss": 0.0, "train/total_loss": 0.20888391137123108, "train/aux_value_loss/g0_gamma0.9000": 0.5741435289382935, "train/aux_value_loss/g1_gamma0.9500": 0.5552539229393005, "train/grad_norm": 0.0591939315199852, "train/pi_loss": -0.6082847118377686, "train/pi_grad_norm": 0.01691805012524128, "train/pi_entropy": -111.1514892578125, "train/pi_scaled_entropy": 492.557861328125, "train/pi_scale": 46.091373443603516}