{"eval/episode_reward": 5.278072834014893, "eval/episode_success": 0.0, "eval/episode_length": 500.0, "eval/step": 0, "eval/episode": 0, "eval/elapsed_time": 72.15981197357178, "eval/steps_per_second": 0.0, "_timestamp": 1757520352.9892707, "_runtime": 880.4449706077576, "_step": 14000, "train/episode_reward": 30.90397071838379, "train/episode_success": 0.0, "train/episode_length": 501, "train/episode_terminated": 0.0, "train/step": 14000, "train/episode": 27, "train/elapsed_time": 876.9789590835571, "train/steps_per_second": 15.96389497717254, "train/consistency_loss": 0.00427796458825469, "train/reward_loss": 0.02352258563041687, "train/value_loss": 0.2905663847923279, "train/aux_value_loss_mean": 0.44420427083969116, "train/termination_loss": 0.0, "train/total_loss": 0.16138862073421478, "train/aux_value_loss/g0_gamma0.9000": 0.44590532779693604, "train/aux_value_loss/g1_gamma0.9500": 0.4425032138824463, "train/grad_norm": 0.0678655281662941, "train/pi_loss": -0.08653125911951065, "train/pi_grad_norm": 8.97622726370173e-07, "train/pi_entropy": -10.433490753173828, "train/pi_scaled_entropy": 3.379716396331787, "train/pi_scale": 1.0872703790664673}