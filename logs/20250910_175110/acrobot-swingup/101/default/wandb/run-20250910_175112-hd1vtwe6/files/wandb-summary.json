{"eval/episode_reward": 5.278072834014893, "eval/episode_success": 0.0, "eval/episode_length": 500.0, "eval/step": 0, "eval/episode": 0, "eval/elapsed_time": 72.15981197357178, "eval/steps_per_second": 0.0, "_timestamp": 1757519979.2627413, "_runtime": 506.71844124794006, "_step": 7000, "train/episode_reward": 4.741561412811279, "train/episode_success": 0.0, "train/episode_length": 501, "train/episode_terminated": 0.0, "train/step": 7000, "train/episode": 13, "train/elapsed_time": 503.2524108886719, "train/steps_per_second": 13.909521044596687, "train/consistency_loss": 0.0033890705090016127, "train/reward_loss": 0.013739628717303276, "train/value_loss": 0.2441844642162323, "train/aux_value_loss_mean": 0.23391564190387726, "train/termination_loss": 0.0, "train/total_loss": 0.1169653832912445, "train/aux_value_loss/g0_gamma0.9000": 0.23035357892513275, "train/aux_value_loss/g1_gamma0.9500": 0.23747770488262177, "train/grad_norm": 0.03835025802254677, "train/pi_loss": -0.05669820308685303, "train/pi_grad_norm": 0.00023779454932082444, "train/pi_entropy": -9.612415313720703, "train/pi_scaled_entropy": 3.4401047229766846, "train/pi_scale": 1.0}