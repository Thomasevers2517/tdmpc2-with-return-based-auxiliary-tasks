{"eval/episode_reward": 5.276887893676758, "eval/episode_success": 0.0, "eval/episode_length": 500.0, "eval/step": 0, "eval/episode": 0, "eval/elapsed_time": 145.60795140266418, "eval/steps_per_second": 0.0, "_timestamp": 1757512294.31779, "_runtime": 669.4482021331787, "_step": 4000, "train/episode_reward": 2.082995678165389e-07, "train/episode_success": 0.0, "train/episode_length": 501, "train/episode_terminated": 0.0, "train/step": 4000, "train/episode": 7, "train/elapsed_time": 665.181524515152, "train/steps_per_second": 6.013396122081988, "train/consistency_loss": 0.0026205198373645544, "train/reward_loss": 0.02115200273692608, "train/value_loss": 0.3301612436771393, "train/aux_value_loss_mean": 0.36800625920295715, "train/termination_loss": 0.0, "train/total_loss": 0.12434234470129013, "train/aux_value_loss/g0_gamma0.9000": 0.3639993369579315, "train/aux_value_loss/g1_gamma0.9500": 0.3720131814479828, "train/grad_norm": 0.05420275777578354, "train/pi_loss": -0.05862358212471008, "train/pi_grad_norm": 0.002330661518499255, "train/pi_entropy": -8.012608528137207, "train/pi_scaled_entropy": 2.632876396179199, "train/pi_scale": 1.0000059604644775}