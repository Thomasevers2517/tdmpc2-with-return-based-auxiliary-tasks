{"eval/episode_reward": 5.276887893676758, "eval/episode_success": 0.0, "eval/episode_length": 500.0, "eval/step": 0, "eval/episode": 0, "eval/elapsed_time": 145.60795140266418, "eval/steps_per_second": 0.0, "_timestamp": 1757514339.5643258, "_runtime": 2714.6947379112244, "_step": 23000, "train/episode_reward": 0.16373783349990845, "train/episode_success": 0.0, "train/episode_length": 501, "train/episode_terminated": 0.0, "train/step": 23000, "train/episode": 45, "train/elapsed_time": 2710.4280185699463, "train/steps_per_second": 8.485744628678637, "train/consistency_loss": 0.00409869197756052, "train/reward_loss": 0.023894671350717545, "train/value_loss": 0.3471340239048004, "train/aux_value_loss_mean": 0.4839552044868469, "train/termination_loss": 0.0, "train/total_loss": 0.1674722284078598, "train/aux_value_loss/g0_gamma0.9000": 0.48232120275497437, "train/aux_value_loss/g1_gamma0.9500": 0.4855892062187195, "train/grad_norm": 0.09294579178094864, "train/pi_loss": -0.12775494158267975, "train/pi_grad_norm": 0.01617569290101528, "train/pi_entropy": -7.808687210083008, "train/pi_scaled_entropy": 2.3808627128601074, "train/pi_scale": 1.0346499681472778}