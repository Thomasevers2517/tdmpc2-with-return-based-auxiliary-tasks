{"eval/episode_reward": 108.1734390258789, "eval/episode_success": 0.0, "eval/episode_length": 500.0, "eval/step": 0, "eval/episode": 0, "eval/elapsed_time": 206.94547748565674, "eval/steps_per_second": 0.0, "_timestamp": 1757512258.6599545, "_runtime": 633.3301086425781, "_step": 3000, "train/episode_reward": 25.729454040527344, "train/episode_success": 0.0, "train/episode_length": 501, "train/episode_terminated": 0.0, "train/step": 3000, "train/episode": 5, "train/elapsed_time": 628.7275371551514, "train/steps_per_second": 4.771542238430204, "train/consistency_loss": 0.005579098593443632, "train/reward_loss": 0.1597413867712021, "train/value_loss": 0.5214771032333374, "train/aux_value_loss_mean": 0.6699393391609192, "train/termination_loss": 0.0, "train/total_loss": 0.24669776856899261, "train/aux_value_loss/g0_gamma0.9000": 0.6871446967124939, "train/aux_value_loss/g1_gamma0.9500": 0.6527339220046997, "train/grad_norm": 0.13093028962612152, "train/pi_loss": -0.4037848711013794, "train/pi_grad_norm": 0.006051961798220873, "train/pi_entropy": -119.84605407714844, "train/pi_scaled_entropy": 490.16497802734375, "train/pi_scale": 28.9851016998291}