{"eval/episode_reward": 108.1734390258789, "eval/episode_success": 0.0, "eval/episode_length": 500.0, "eval/step": 0, "eval/episode": 0, "eval/elapsed_time": 206.94547748565674, "eval/steps_per_second": 0.0, "_timestamp": 1757514336.5649598, "_runtime": 2711.2351138591766, "_step": 21000, "train/episode_reward": 26.988327026367188, "train/episode_success": 0.0, "train/episode_length": 501, "train/episode_terminated": 0.0, "train/step": 21000, "train/episode": 41, "train/elapsed_time": 2706.6326129436493, "train/steps_per_second": 7.7587183053857665, "train/consistency_loss": 0.004387993365526199, "train/reward_loss": 0.18698710203170776, "train/value_loss": 0.3309674859046936, "train/aux_value_loss_mean": 0.6114569902420044, "train/termination_loss": 0.0, "train/total_loss": 0.2007010132074356, "train/aux_value_loss/g0_gamma0.9000": 0.6161293983459473, "train/aux_value_loss/g1_gamma0.9500": 0.6067845821380615, "train/grad_norm": 0.06902078539133072, "train/pi_loss": -0.30371978878974915, "train/pi_grad_norm": 0.006326209753751755, "train/pi_entropy": -108.32681274414062, "train/pi_scaled_entropy": 492.11419677734375, "train/pi_scale": 86.13164520263672}